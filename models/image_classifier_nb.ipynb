{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree species image classification using Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sciapps/Documents/Repos/tfm/env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tfm/data/images/image_preprocessing/processed_images/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d6a1dfb2e07a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# LABELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tfm/data/images/image_preprocessing/processed_images/train'"
     ]
    }
   ],
   "source": [
    "# DATA SET DIRECTORIES\n",
    "source_dir = \"tfm/data/images/image_preprocessing/processed_images/\"\n",
    "train_dir = os.path.join(source_dir, \"train\")\n",
    "test_dir = os.path.join(source_dir, \"test\")\n",
    "val_dir = os.path.join(source_dir, \"val\")\n",
    "############################################\n",
    "# LABELS\n",
    "class_names = os.listdir(train_dir)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image decodification and augmentation\n",
    "\n",
    "Aim: increase the number of examples by randomly applying transformations to the original images. It also prevents overfitting of the model. \n",
    "\n",
    "Augmnetation methods:\n",
    "\n",
    "- Rotation.\n",
    "- Width shift.\n",
    "- Height shift.\n",
    "- Horizontal flip\n",
    "- Zooming\n",
    "\n",
    "`ImageDataGenrator`:\n",
    "\n",
    "- Read images from the disk.\n",
    "- Decode images in arrays of float pixel values (here RGB).\n",
    "- Rescale the floats in the arrays from values between 0 and 255 to 0 and 1.\n",
    "- Perform real-time image augmentation.\n",
    "\n",
    "`flow_from_directory`:\n",
    "\n",
    "- Generate the batches of array image data (aka tensors) with the real-time data augmentation defined in the `ImageDataGenerator`.\n",
    "- Resize the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "# Parameters for ImageDataGenerator \n",
    "color_mode= \"rgb\"   \n",
    "img_height = 28 \n",
    "img_width = 28   \n",
    "class_mode=\"categorical\" \n",
    "batch_size = 3 \n",
    "epochs = 15                                     \n",
    "shuffle=True                                                               \n",
    "seed = 1234 \n",
    "# Parameters for test dataset \n",
    "test_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                            rotation_range=45,\n",
    "                                            width_shift_range=.15,\n",
    "                                            height_shift_range=.15,\n",
    "                                            horizontal_flip=True,\n",
    "                                            zoom_range=0.5,\n",
    "                                            validation_split = 0.16)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            color_mode = color_mode,\n",
    "                                            batch_size = batch_size,                               \n",
    "                                            shuffle = shuffle,\n",
    "                                            class_mode = class_mode,\n",
    "                                            subset = \"training\",\n",
    "                                            seed=seed\n",
    "                                            ) \n",
    "validation_generator = train_datagen.flow_from_directory(train_dir,  # same directory as training data\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    color_mode = color_mode,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode= class_mode,\n",
    "                                                    subset='validation',\n",
    "                                                    seed=seed) # set as validation data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating, training and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model network architecture\n",
    "\n",
    "The simplest network architecture constists of 3 layers:\n",
    "- Input layer, with a number of nodes equal to the number of features in the model.\n",
    "- Hidden layer, with a variable number of nodes. \n",
    "- Output layer, with a number of nodes equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model with `Keras`\n",
    "\n",
    "In `Keras` the model is defined with the `Sequential` method as a linear stack ot layers.\n",
    "\n",
    "Ty\n",
    "the number of output channels for each Conv2D layer is controlled by the first argument (e.g., 32 or 64).\n",
    "    ## Typically, as the width and height shrink, you can afford (computationally) to add more output channels in each Conv2D layer\n",
    "    # For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one for each class.\n",
    "    # The tf.nn.softmax function converts these logits to \"probabilities\" for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PARAMETERS\n",
    "array_size = img_width*img_height\n",
    "dense_size = 128 \n",
    "num_classes = 42\n",
    "kernel_size = 3,3 # number of convolutional filters (width*height of the filter mask)\n",
    "padding = \"same\" # case insensitive. Other option: \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL ARCHITECTURE\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(dense_size, activation = \"relu\", input_shape=(1,28,28,3)))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation = \"softmax\")) # last layer\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILING THE MODEL\n",
    "# SparseCategoricalCrossentropi directly uses classes labels,\n",
    "## so that they don't need to be numerically encoded.\n",
    "optimizer = \"adam\" # Options: \"sgd\", \"adam\"\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss = \"sparse_categorical_crossentropy\",\n",
    "            #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE MODEL\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=3, # batch_size,\n",
    "    epochs=15,\n",
    "    verbose=1, # get a progress bar and ETA\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2 # batch_size\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
