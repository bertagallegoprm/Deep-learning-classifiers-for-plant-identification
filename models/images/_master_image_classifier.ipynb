{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree species image classification using Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "local_path = \"/home/sciapps/Documents/Repos/tfm\"\n",
    "model_name = \"VGG16_pretrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SET DIRECTORIES\n",
    "source_dir = \"data/images/image_preprocessing/processed_images_train_test/\"\n",
    "train_dir = os.path.join(local_path, source_dir, \"train\")\n",
    "test_dir = os.path.join(local_path, source_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUTS\n",
    "save_dir = os.path.join(local_path, \"models\", \"images\", \"outputs\", model_name)\n",
    "# Create outputs folder\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image decodification\n",
    "\n",
    "`ImageDataGenrator`:\n",
    "\n",
    "- Read images from the disk.\n",
    "- Decode images in arrays of float pixel values (here RGB).\n",
    "- Rescale the floats in the arrays from values between 0 and 255 to 0 and 1.\n",
    "- Perform real-time image augmentation.\n",
    "\n",
    "`flow_from_directory`:\n",
    "\n",
    "- Generate the batches of array image data (aka tensors) with the real-time data augmentation defined in the `ImageDataGenerator`.\n",
    "- Resize the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION ImageDataGenerator \n",
    "img_height = 224 \n",
    "img_width = 224\n",
    "color_mode= \"rgb\"\n",
    "class_mode=\"categorical\"                                  \n",
    "shuffle=True                                                               \n",
    "seed = 1234 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_no_aug = ImageDataGenerator(rescale=1./255)  \n",
    "train_array_no_aug = train_datagen_no_aug.flow_from_directory(directory = train_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            color_mode = color_mode,\n",
    "                                            shuffle = shuffle,\n",
    "                                            class_mode = class_mode,\n",
    "                                            subset = \"training\",\n",
    "                                            seed=seed\n",
    "                                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_array_no_aug)\n",
    "plot_images(sample_training_images[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying augmentation\n",
    "\n",
    "Aim: increase the number of examples by randomly applying transformations to the original images. It also prevents overfitting of the model. \n",
    "\n",
    "Augmnetation methods applied:\n",
    "\n",
    "- Rotation\n",
    "- Vertica flip\n",
    "- Horizontal flip\n",
    "\n",
    "Other augmentation methods that were found not suitable (leave shape distorsion):\n",
    "- Width shift \n",
    "- Height shift\n",
    "- Zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                            rotation_range=45,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            validation_split = 0.20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            color_mode = color_mode,\n",
    "                                            shuffle = shuffle,\n",
    "                                            class_mode = class_mode,\n",
    "                                            subset = \"training\",\n",
    "                                            seed=seed\n",
    "                                            ) \n",
    "validation_array = train_datagen.flow_from_directory(train_dir,  # same directory as training data\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    color_mode = color_mode,\n",
    "                                                    #batch_size=batch_size,\n",
    "                                                    class_mode= class_mode,\n",
    "                                                    subset='validation',\n",
    "                                                    seed=seed) # set as validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_array[8][0][0] for i in range(5)]\n",
    "plot_images(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating, training and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model network architecture\n",
    "\n",
    "The simplest network architecture constists of 3 layers:\n",
    "- Input layer, with a number of nodes equal to the number of features in the model.\n",
    "- Hidden layer, with a variable number of nodes. \n",
    "- Output layer, with a number of nodes equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The hidden layers\n",
    "\n",
    "The hidden layers can have different characteristics depending of their use. \n",
    "For image classification, at least one of the hidden layers will be convolutional.\n",
    "\n",
    "##### The convolutional layer\n",
    "\n",
    "The main characteristic of a convolutional layer is that it applies a filter to each of the elements of a matrix (the pixels of an image). This filter is called the **kernel**. The kernel is a matrix (generally of small size, 2x3, 3x2, 3x3...) with a set of fixed real numbers. Each pixel of the original image is multiplied by the kernel matrix and the result sumed up to output another pixel value for the transformed image. Each time the filter is applied to all the pixels of an image is called a **convolution**.\n",
    "\n",
    "At this level , the performance of the image feature extraction depends on the values in the kernel and the concatenation of convolutional layers. This is because different filters may be specialized in extracting different features (for example, vertical or horizontal edges) and the sequential input and output values for each layer improves the final output.\n",
    "\n",
    "In keras, the convolutional layer applied to a 2D matrix is called `Conv2D`.\n",
    "\n",
    "##### The fully connected layer\n",
    "\n",
    "A fully connected layer is an all purpose layer where each node receive the inputs from all the nodes from the previous layer, multiplied by their weights, sumed and transformed by the activation funcion.\n",
    "\n",
    "In keras, the fully connected layer is called `Dense`.\n",
    "\n",
    "\n",
    "##### MaxPooling2D\n",
    "\n",
    "\n",
    "##### Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model with `Keras`\n",
    "\n",
    "In `Keras` the model is defined with the `Sequential` method as a linear stack ot layers. The **input layer** is implicit in the first layer (a network with 3 layers will have 2 in `keras Sequential` method).\n",
    "\n",
    "The **input shape** is into the first layer. The model inputs are the tensors or arrays. Images have 3 dimensions: **width**, **height** and **channels**. The width and the height are measured in pixels and the channels reference the color values (the channel value is 1 if it is in black and white and 3 if it is color in RGB (Red, Green, blue) or HSV (hue, saturation, value) formats - 2 and 4 are black and white or color with an alpha channel (transparency). \n",
    "\n",
    "The **activation function** that has to be specified in each layer transforms the input data so that the output doen't have a linear relation with the input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with `Keras`\n",
    "\n",
    "Aim: to use a pre-existing model that has performed well carrying out a similar task. \n",
    "\n",
    "#### VGG16\n",
    "\n",
    "Ref: 2014 ImageNet competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model with the weights\n",
    "vgg16_model = tf.keras.applications.VGG16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the layers of vgg16 model to a new sequential model \n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]: # remove last layer\n",
    "    model.add(layer)\n",
    "# Rename model\n",
    "model._name = model_name\n",
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights in the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# Add last layer for categories\n",
    "model.add(Dense(len(class_names), activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-trainable parameters are no longer 0, since it has been selected to freeze the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from the model above represent the **weights**. \n",
    "A weight is a number that multiplies the value of the **input node** before passing it to the **output node** in the next layer. \n",
    "An output node receive the values from each of the input nodes multiplied by their weights, after they have been sumed and transformed by the **activation function**.\n",
    "\n",
    "\n",
    "Training the model means to adjust the values of the weights in the subsequent runs (the **epochs**. In every run, the weights are modified based on an optimization algorithm or **optimizer**.\n",
    "This algorithm tries to minimize the **loss function**. In every run, the model predicts the classes with a certain probability. The loss function measures, through that probability, the error of the predictions. In this context, the **gradient** is the computation of the error in relation to the weight (it is the derivative of the error divided into the derivative of the weight). The gradient is multiplied by a **learning rate** to obtain the new weights. The value of the learning rate is in the order of 10^-3.\n",
    "\n",
    "**Stocastic gradient descent** (sgd) is one type of optimizer. There are also different types of loss functions, like the **sparse categorical crossentropy**. The value of the optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "\n",
    "- Epoch: the number of iterations through the network in order to adjust the weights. In general, the higher number of epochs, the better the performance, up to a limit. \n",
    "- Batch size: the number of examples passed at a time. If the batch size is equal to the number of examples in the training dataset, then we have one batch per epoch. This is computationally costly and may be limited by the machine power. If the batch size is smaller, then there would be several runs per epoch. If it is too small, the training may be too slow.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "batch_size = round(len(train_array)/4)\n",
    "epochs = 30  \n",
    "steps_per_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILING THE MODEL\n",
    "# SparseCategoricalCrossentropi directly uses classes labels,\n",
    "## so that they don't need to be numerically encoded.\n",
    "optimizer = \"sgd\" # Options: \"sgd\", \"adam\"\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE MODEL\n",
    "history = model.fit_generator(\n",
    "    train_array,\n",
    "    #batch_size = batch_size,\n",
    "    steps_per_epoch= 4,\n",
    "    epochs=epochs,\n",
    "    verbose=1, # get a progress bar and ETA\n",
    "    validation_data=validation_array,\n",
    "    validation_steps=2 # batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters measured during model training\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict[\"acc\"]\n",
    "val_acc = history_dict[\"val_acc\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "epochs_range = range(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.suptitle(model_name)\n",
    "# Accuracy plots\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "# Loss plots\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\") \n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.savefig(os.path.join(save_dir,\"acc_loss_plot.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model, model summary and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT FOR EACH MODEL\n",
    "# Model description\n",
    "model_description = f\"\"\"\n",
    "{model_name}\n",
    "# load pre-trained model with the weights\n",
    "vgg16_model = tf.keras.applications.VGG16()\n",
    "# Add the layers of vgg16 model to a new sequential model \n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]: # remove last layer\n",
    "    model.add(layer)\n",
    "# Freeze the weights in the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# Add last layer for categories\n",
    "model.add(Dense(len(class_names), activation = \"softmax\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model means saving:\n",
    "\n",
    "- the model's configuration (topology)\n",
    "- the model's weights\n",
    "- the model's optimizer's state (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights(os.path.join(save_dir, \"weights.h5\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights independently\n",
    "model.save(os.path.join(save_dir, \"model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the model again, it has to be built and then the weights added:\n",
    "\n",
    "```\n",
    "# load pre-trained model with the weights\n",
    "vgg16_model = tf.keras.applications.VGG16()\n",
    "# Add the layers of vgg16 model to a new sequential model \n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]: # remove last layer\n",
    "    model.add(layer)\n",
    "# Freeze the weights in the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# Add last layer for categories\n",
    "model.add(Dense(len(class_names), activation = \"softmax\"))  \n",
    "\n",
    "cnn.load_weights(os.path.join(save_dir, \"model.h5\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model description\n",
    "with open(os.path.join(save_dir,\"model_description.txt\"), \"w\") as file:\n",
    "    with redirect_stdout(file):\n",
    "        print(model_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model summary\n",
    "with open(os.path.join(save_dir,\"model_summary.txt\"), \"w\") as file:\n",
    "    with redirect_stdout(file):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model history to csv\n",
    "history_df = pd.DataFrame(history.history) \n",
    "history_df.to_csv(os.path.join(save_dir, \"model_history.csv\"), sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get back the accuracy and loss data:\n",
    "\n",
    "- Open the CSV with the model history.\n",
    "- Save it to a dictionary.\n",
    "\n",
    "```\n",
    "history_df = pd.read_csv(os.path.join(save_dir, \"model_history.csv\"))\n",
    "history = history_df.to_dict()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting\n",
    "\n",
    "When the model predicts significantly better the training set than the validation set, it is a sign of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
