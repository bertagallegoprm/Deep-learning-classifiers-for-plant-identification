{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.utils import plot_model \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import redirect_stdout\n",
    "import pandas as pd\n",
    "import pydot_ng as pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "local_path = \"/home/sciapps/Documents/Repos/tfm\"\n",
    "model_name = \"vgg19_b1b2b3_pretrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SET DIRECTORIES\n",
    "source_dir = \"data/images/image_preprocessing/processed_images_train_val_test/\"\n",
    "train_dir = os.path.join(local_path, source_dir, \"train\")\n",
    "val_dir = os.path.join(local_path, source_dir, \"val\")\n",
    "test_dir = os.path.join(local_path, source_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUTS\n",
    "save_dir = os.path.join(os.path.abspath(os.getcwd()), \"outputs\", model_name)\n",
    "# Create outputs folder\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image decodification\n",
    "\n",
    "`ImageDataGenrator`:\n",
    "\n",
    "- Read images from the disk.\n",
    "- Decode images in arrays of float pixel values (here RGB).\n",
    "- Rescale the floats in the arrays from values between 0 and 255 to 0 and 1.\n",
    "- Perform real-time image augmentation.\n",
    "\n",
    "`flow_from_directory`:\n",
    "\n",
    "- Generate the batches of array image data (aka tensors) with the real-time data augmentation defined in the `ImageDataGenerator`.\n",
    "- Resize the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION ImageDataGenerator \n",
    "img_height = 224 \n",
    "img_width = 224\n",
    "color_mode= \"rgb\"\n",
    "class_mode=\"categorical\"                                  \n",
    "shuffle=True                                                               \n",
    "seed = 1234 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(15,15))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_no_aug = ImageDataGenerator(rescale=1./255)  \n",
    "train_array_no_aug = train_datagen_no_aug.flow_from_directory(directory = train_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            color_mode = color_mode,\n",
    "                                            shuffle = shuffle,\n",
    "                                            class_mode = class_mode,\n",
    "                                            subset = \"training\",\n",
    "                                            seed=seed\n",
    "                                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_array_no_aug)\n",
    "plot_images(sample_training_images[:24])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying augmentation\n",
    "\n",
    "Aim: increase the number of examples by randomly applying transformations to the original images. It also prevents overfitting of the model. \n",
    "\n",
    "Augmnetation methods applied:\n",
    "\n",
    "- Rotation\n",
    "- Vertica flip\n",
    "- Horizontal flip\n",
    "- Brightness range  (Values less than 1.0 darken the image, e.g. [0.5, 1.0], whereas values larger than 1.0 brighten the image, e.g. [1.0, 1.5], where 1.0 has no effect on brightness)\n",
    "- Zooming\n",
    "- Shear range\n",
    "\n",
    "Fill mode for empty pixels when rotating the image is set to \"reflect\", so that, being the letters between brachets the pixels of the image, the area outside is filled as follow: abcddcba|abcd|dcbaabcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation in train dataset \n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                            brightness_range = [0.2,1.5],\n",
    "                                            zoom_range = [0.5,1.0],\n",
    "                                            rotation_range=45,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            shear_range = 0.2,\n",
    "                                            fill_mode = \"reflect\") \n",
    "\n",
    "train_array = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            color_mode = color_mode,\n",
    "                                            shuffle = shuffle,\n",
    "                                            class_mode = class_mode,\n",
    "                                            #subset = \"training\",\n",
    "                                            seed=seed\n",
    "                                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "validation_array = val_datagen.flow_from_directory(val_dir, \n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    color_mode = color_mode,\n",
    "                                                    class_mode= class_mode,\n",
    "                                                    #subset='validation',\n",
    "                                                    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_array[0][0][0] for i in range(6)]\n",
    "plot_images(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model network architecture\n",
    "\n",
    "The simplest network architecture constists of 3 layers:\n",
    "\n",
    "- Input layer, with a number of nodes equal to the number of features in the model.\n",
    "- Hidden layer, with a variable number of nodes. \n",
    "- Output layer, with a number of nodes equal to the number of classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The hidden layers\n",
    "\n",
    "The hidden layers can have different characteristics depending of their use. \n",
    "The transformations applied by the convolutional layers have shown the best results for image classification, so they will be the main component in this model.\n",
    "\n",
    "##### The convolutional layer \n",
    "\n",
    "The main characteristic of a convolutional layer is that it applies a filter to each of the elements of a matrix (the pixels of an image). This filter is called the **kernel**. The kernel is a matrix (generally of small size, 2x3, 3x2, 3x3...) with a set of fixed real numbers. Each pixel of the original image is multiplied by the kernel matrix and the result sumed up to output another pixel value for the transformed image. Each time the filter is applied to all the pixels of an image is called a **convolution**.\n",
    "\n",
    "At this level , the performance of the image feature extraction depends on the values in the kernel and the concatenation of convolutional layers. This is because different filters may be specialized in extracting different features (for example, vertical or horizontal edges) and the sequential input and output values for each layer improves the final output.\n",
    "\n",
    "In keras, the convolutional layer applied to a 2D matrix is called `Conv2D`.\n",
    "\n",
    "\n",
    "##### The pooling layer\n",
    "\n",
    "Pooling, in the context of deep learning and image classification, is a technique by which the dimension of an image is reduced. This is done by applying a filter (a matrix of n x n dimension) to the pixels of the image. For example, a filter of 3 x 3 pixels, would take the 3 x 3 pixels on the top left of the input image, apply a calculation to them as a group (as a **_pool_** of numbers), resulting on a single pixel value for the output image. This filter is set to slide through the image by a fixed amount of pixels. This parameter is called the **stride**. If the stride was three in the example above, then the 3 x 3 filter would go through the image without overlapping. \n",
    "\n",
    "One type of pooling calculation -and the most used- is to select the maximum number of the n x n pool. The pooling layer that performs this operation is known as **max pooling layer** (in `keras` is `MaxPooling2D`).\n",
    "\n",
    "The max pooling layers are often added after a convolutional layer. By reducing the dimesion of the image and selecting the maximum values, it passes to the next layer the most activated pixels. This filter helps reducing the overfitting of the model to the original images. Moreover, it sreduces the computational load. \n",
    "\n",
    "##### The fully connected layer\n",
    "\n",
    "A fully connected layer is an all purpose layer where each node receive the inputs from all the nodes from the previous layer, multiplied by their weights, sumed and transformed by the activation funcion.\n",
    "\n",
    "In keras, the fully connected layer is called `Dense`.\n",
    "\n",
    "##### Flatten\n",
    "\n",
    "In a classification model, the outlput layer must have as many nodes as classes, so that it computes a value for each class. To do that, the last layer needs a 1D array as an input. In a CNN, the arrays representing images have more than one dimension (width, height and color), so this dimensionality must be reduced. The flatten layer transforms the image 2D array into a 1D array before passing it to the last layer (or layers). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model with `Keras`\n",
    "\n",
    "In `Keras` the model is defined with the `Sequential` method as a linear stack ot layers. The **input layer** is implicit in the first layer (a network with 3 layers will have 2 in `keras Sequential` method).\n",
    "\n",
    "The **input shape** is into the first layer. The model inputs are the tensors or arrays. Images have 3 dimensions: **width**, **height** and **channels**. The width and the height are measured in pixels and the channels reference the color values (the channel value is 1 if it is in black and white and 3 if it is color in RGB (Red, Green, blue) or HSV (hue, saturation, value) formats - 2 and 4 are black and white or color with an alpha channel (transparency). \n",
    "\n",
    "The **activation function** that has to be specified in each layer transforms the input data so that the output doen't have a linear relation with the input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with `Keras`\n",
    "\n",
    "Aim: to use a pre-existing model that has performed well carrying out a similar task. \n",
    "\n",
    "\n",
    "#### VGG16\n",
    "\n",
    "Ref: 2014 ImageNet competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model with the weights\n",
    "loaded_model = tf.keras.applications.VGG19()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the layers of vgg16 model to a new sequential model \n",
    "model = Sequential()\n",
    "for layer in loaded_model.layers[:-1]: # remove last layer\n",
    "    model.add(layer)\n",
    "# Rename model\n",
    "model._name = model_name\n",
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_layer = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights in the layers of first blocks\n",
    "for layer in model.layers[:limit_layer]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[limit_layer:]:\n",
    "    layer.trainable = True\n",
    "# Add last layer for categories\n",
    "model.add(Dense(len(class_names), activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "# Save model summary\n",
    "with open(os.path.join(save_dir,\"model_summary.txt\"), \"w\") as file:\n",
    "    with redirect_stdout(file):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-trainable parameters are no longer 0, since it has been selected to freeze the weights of blocks 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model architecture and save it as .png\n",
    "rankdir = \"TB\" # TB: vertical; LR: horizontal\n",
    "plot_model(model, to_file = os.path.join(save_dir,\"model_plot.png\"), \n",
    "           show_shapes=True, show_layer_names = True, rankdir = rankdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from the model above represent the **weights**. \n",
    "A weight is a number that multiplies the value of the **input node** before passing it to the **output node** in the next layer. \n",
    "An output node receive the values from each of the input nodes multiplied by their weights, after they have been sumed and transformed by the **activation function**.\n",
    "\n",
    "\n",
    "Training the model means to adjust the values of the weights in the subsequent runs (the **epochs**. In every run, the weights are modified based on an optimization algorithm or **optimizer**.\n",
    "This algorithm tries to minimize the **loss function**. In every run, the model predicts the classes with a certain probability. The loss function measures, through that probability, the error of the predictions. In this context, the **gradient** is the computation of the error in relation to the weight (it is the derivative of the error divided into the derivative of the weight). The gradient is multiplied by a **learning rate** to obtain the new weights. The value of the learning rate is in the order of 10^-3.\n",
    "\n",
    "**Stocastic gradient descent** (sgd) is one type of optimizer. There are also different types of loss functions, like the **sparse categorical crossentropy**. The value of the optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "\n",
    "- Epoch: the number of iterations through the network in order to adjust the weights. In general, the higher number of epochs, the better the performance, up to a limit. \n",
    "- Batch size: the number of examples passed at a time. If the batch size is equal to the number of examples in the training dataset, then we have one batch per epoch. This is computationally costly and may be limited by the machine power. If the batch size is smaller, then there would be several runs per epoch. If it is too small, the training may be too slow.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "batch_size = 100\n",
    "epochs = 100  \n",
    "steps_per_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILING THE MODEL\n",
    "# SparseCategoricalCrossentropi directly uses classes labels,\n",
    "## so that they don't need to be numerically encoded.\n",
    "optimizer = \"sgd\" # Options: \"sgd\", \"adam\"\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping (when loss does not fall anymore to avoid overfitting)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience = 30)\n",
    "\n",
    "# Checkpoint to save model weights and history before it stops training\n",
    "checkpoint_filepath = os.path.join(save_dir, \"/tmp/checkpoint\")\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath,\n",
    "                                                              save_weights_only = True,\n",
    "                                                              monitor= \"val_accuracy\",\n",
    "                                                              save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAINING THE MODEL\n",
    "history = model.fit_generator(\n",
    "    train_array,\n",
    "    #batch_size = batch_size,\n",
    "    steps_per_epoch= 4,\n",
    "    epochs=epochs,\n",
    "    verbose=1, # get a progress bar and ETA\n",
    "    validation_data=validation_array,\n",
    "    validation_steps=2, # batch_size\n",
    "    callbacks = [callback, model_checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Save model history to csv\n",
    "history_df = pd.DataFrame(history.history) \n",
    "history_df.to_csv(os.path.join(save_dir, \"model_history.csv\"), sep=\",\", index=False)\n",
    "\n",
    "# Save model weights\n",
    "model.save_weights(os.path.join(save_dir, \"weights.h5\")) \n",
    "\n",
    "# Save model \n",
    "# model.save(os.path.join(save_dir, \"model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and loss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters measured during model training\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    acc = history_dict[\"acc\"]\n",
    "    val_acc = history_dict[\"val_acc\"]\n",
    "    loss = history_dict[\"loss\"]\n",
    "    val_loss = history_dict[\"val_loss\"]\n",
    "    epochs_range = range(epochs)\n",
    "except:\n",
    "    try:\n",
    "        acc = history_dict[\"accuracy\"]\n",
    "        val_acc = history_dict[\"val_accuracy\"]\n",
    "        loss = history_dict[\"loss\"]\n",
    "        val_loss = history_dict[\"val_loss\"]\n",
    "        epochs_range = range(epochs)\n",
    "    except:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.suptitle(model_name)\n",
    "# Accuracy plots\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "# Loss plots\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\") \n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(os.path.join(save_dir,\"acc_loss_plot.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting\n",
    "\n",
    "When the model predicts significantly better the training set than the validation set, it is a sign of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model, model summary and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT FOR EACH MODEL\n",
    "# Model description\n",
    "model_description = f\"\"\"\n",
    "{model_name}\n",
    "# load pre-trained model with the weights\n",
    "vgg16_model = tf.keras.applications.VGG16()\n",
    "# Add the layers of vgg16 model to a new sequential model \n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]: # remove last layer\n",
    "    model.add(layer)\n",
    "# Freeze the weights in the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# Add last layer for categories\n",
    "model.add(Dense(len(class_names), activation = \"softmax\"))\n",
    "\"\"\"\n",
    "\n",
    "# Save model description\n",
    "with open(os.path.join(save_dir,\"model_description.txt\"), \"w\") as file:\n",
    "    with redirect_stdout(file):\n",
    "        print(model_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model means saving:\n",
    "\n",
    "- the model's configuration (topology)\n",
    "- the model's weights\n",
    "- the model's optimizer's state (if any)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the model again, it has to be built and then the weights added:\n",
    "\n",
    "```\n",
    "# load pre-trained model with the weights\n",
    "vgg16_model = tf.keras.applications.VGG16()\n",
    "# Add the layers of vgg16 model to a new sequential model \n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]: # remove last layer\n",
    "    model.add(layer)\n",
    "# Freeze the weights in the layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# Add last layer for categories\n",
    "model.add(Dense(len(class_names), activation = \"softmax\"))  \n",
    "\n",
    "cnn.load_weights(os.path.join(save_dir, \"model.h5\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get back the accuracy and loss data:\n",
    "\n",
    "- Open the CSV with the model history.\n",
    "- Save it to a dictionary.\n",
    "\n",
    "```\n",
    "# Recover saved history from file\n",
    "history_df = pd.read_csv(os.path.join(save_dir, \"model_history.csv\"))\n",
    "history_dict = history_df.to_dict()\n",
    "try: # the key names vary across tf versions\n",
    "    acc = np.array(list(history_dict[\"acc\"].values()))\n",
    "    val_acc = np.array(list(history_dict[\"val_acc\"].values()))\n",
    "    loss = np.array(list(history_dict[\"loss\"].values()))\n",
    "    val_loss = np.array(list(history_dict[\"val_loss\"].values()))\n",
    "    epochs_range = np.array(range(epochs))\n",
    "except:\n",
    "    try:\n",
    "        acc = np.array(list(history_dict[\"accuracy\"].values()))\n",
    "        val_acc = np.array(list(history_dict[\"val_accuracy\"].values()))\n",
    "        loss = np.array(list(history_dict[\"loss\"].values()))\n",
    "        val_loss = np.array(list(history_dict[\"val_loss\"].values()))\n",
    "        epochs_range = np.array(range(epochs))\n",
    "    except:\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_main_dir = os.path.join(local_path, source_dir)\n",
    "test_batch_size = len(os.listdir(test_dir)) \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "test_array = test_datagen.flow_from_directory(directory = test_main_dir,  \n",
    "                                                    classes = [\"test\"],\n",
    "                                                    batch_size = test_batch_size,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    color_mode = color_mode,\n",
    "                                                    shuffle = False,\n",
    "                                                    class_mode= None,\n",
    "                                                    seed=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST LABELS\n",
    "def get_test_labels(test_files):\n",
    "    \"\"\"\n",
    "    Return a list of labels: \n",
    "        \"Genus_species\"\n",
    "    Arg.: a list of file names with the structure:\n",
    "          \"Genus_species_occurrencenumber.jpg\",\n",
    "          where Genus_species is the class name,   \n",
    "    \"\"\"\n",
    "    test_labels = []\n",
    "    for i in range(len(test_files)):\n",
    "        test_file_split = test_files[i].split(\"_\")\n",
    "        # Remove occurence number and file extension\n",
    "        class_name_splitted = test_file_split[:-1]\n",
    "        class_name = \"_\".join(class_name_splitted)\n",
    "        test_labels.append(class_name)\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_labels_to_index(test_labels, class_names):\n",
    "    \"\"\"\n",
    "    Return a 1D array of integers with the corresponding\n",
    "    number for a class.\n",
    "    Args.: - A list with the class name of each item in \n",
    "          the test data set.\n",
    "           - A sorted list with the possible class names. \n",
    "    Eg.: test_labels[1] = \"Buxus_sempervirens\" corresponds to index 4\n",
    "         in the list of class names.\n",
    "    \"\"\"\n",
    "    test_labels_index = []\n",
    "    for i in range(len(test_labels)):\n",
    "        ind = class_names.index(test_labels[i])\n",
    "        test_labels_index.append(ind)\n",
    "    return np.array(test_labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = os.listdir(test_dir)\n",
    "test_labels = get_test_labels(test_files)\n",
    "test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_index = test_labels_to_index(test_labels, class_names)\n",
    "test_labels_index[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the probability of classifiying each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability of predicting each class for each image\n",
    "predictions = model.predict_generator(test_array,steps=1,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions is a 2D array with a shape: (number of examples in test, number of classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted class for each example\n",
    "def predicted_class(predictions):\n",
    "    \"\"\"\n",
    "    Return a 1D array with the predicted class for each example.\n",
    "    Arg.: 2D array predictions of shape (number of examples, number of classes)\n",
    "    \"\"\"\n",
    "    pred_class = []\n",
    "    for i in range(len(predictions)):\n",
    "        higher_prob = max(predictions[i])\n",
    "        ind, = np.where(np.isclose(predictions[i], higher_prob))\n",
    "        pred_class.append(ind[0])\n",
    "    return np.array(pred_class)\n",
    "\n",
    "pred_class = predicted_class(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the confusion matrix\n",
    "cm = tf.math.confusion_matrix(test_labels_index, pred_class) \n",
    "# Convert from tensor to array\n",
    "sess = tf.Session()\n",
    "conf_mat = sess.run(cm)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.BuGn)\n",
    "    plt.title(\"Confusion matrix - \"+ model_name, fontsize = 22)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=90)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.savefig(os.path.join(save_dir,\"conf_matrix.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf_mat, np.array(class_names), model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
